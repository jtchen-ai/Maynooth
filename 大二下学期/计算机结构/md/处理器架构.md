# 处理器架构

## 1. CISC 与 RISC 架构

### 基本概念 (Core Concepts)

- CISC 和 RISC 是与微处理器相关的两种极端设计理念。

### CISC (Complex Instruction Set Computer - 复杂指令集计算机)

- 特点:

	- 拥有大量的操作数、寻址模式和可能的指令。

		- 优势：大量指令使代码编译器更容易编写

		- 缺陷：但在处理器解码指令时效率较低。

	- 在处理器内部为数学和数据操作功能实现微代码。

		- 优势：这使得这些特定功能比等效的 RISC 处理器快

		- 缺陷：解码指令的额外开销会降低整体性能。

	- Pentium/8086 系列处理器是 CISC 处理器。

### RISC (Reduced Instruction Set Computer - 精简指令集计算机)

- 特点:

	- 机理：

		- 通常在一个时钟周期内执行所有（或几乎所有）指令。

		- 任何数学函数都是硬件实现的，而不是用微代码实现。

	- 需求分析：

		- 为实现此目标，设计通常以牺牲可用的寻址模式和数据格式为代价来提高处理器速度。

		- 需要高性能的编译器来创建高效代码。

		- 需要访问高速内存，以便以处理器能够执行的速率提供指令。

- 设计哲学:

	- 拥有有限且简单的指令集。

	- 大量通用寄存器。

	- 优化的指令流水线。

	- 随着技术进步，RISC 设计利用增加的复杂性来创建新的寄存器、流水线和缓存。

### 设计动机与比较 (Design Rationale & Comparison)

- 问题背景

	- **语义鸿沟 (Semantic Gap)**:

		-  高级语言（HLL）与硬件 / 代码之间的巨大差异。

		- 最初解决：提高硬件功能性

	- 成本上升：

		- 硬件成本相对下降，软件成本上升

		- 最初解决方案：靠高级语言解决

- 性能提升途径:

	- **CISC 方法**: 

		- 动机：为编译程序员准备的指令集

		- 意义：

			- 使机器指令更像高级语言，从而需要更少的指令来执行程序（编译器简化）。

			- 这会产生更小更快的程序

		- 局限：但许多编译器只使用指令集的一个子集。

	- **RISC 方法**: 

		- 指令流水线应当支持分支实现

		- 用寄存器引用替换内存引用。

		- 通过将最常用指令存放至少寄存器，优化性能

- 高级语言观察 (HLL Observations):

	- 主要执行的操作是赋值、条件和分支。

	- 80% 的引用是针对局部变量的。

- 指令结构差异:

	- **CISC**:

		- 更多的指令，需要更多的bit 来定义每条指令

		- 拥有多种寻址模式

	- **RISC**：

		- 每条指令的位数更少

		- 可能需要更多的指令

		- 操作数更有可能是寄存器

- **技术融合**: RISC 和 CISC 技术正在融合，差异不再那么清晰。

## 2. 流水线 (Pipelining)

### 基本原理:

- 采用 “传送带” 的方式执行指令。

- 当第一条指令正在执行时，第二条指令正在解码，第三条正在提取。

- 简单的处理器必须为每条指令完成提取、解码、获取操作数、执行和返回结果的步骤，早期处理器每个步骤需要一个单独的时钟周期。

### Pentium 流水线阶段:

- **预取 (Prefetch)**: 指令存储在缓冲区中。

- **解码 1 (Decode 1)**: 操作码和寻址模式。

- **解码 2 (Decode 2)**: 生成内存访问地址。

- **执行 (Execute)**: ALU。

- **写回 (Write Back)**: 结果放回寄存器，标志位更新。

### 流水线冲突 (Pipeline Conflicts)

- **资源冲突 (Resource conflicts)**: 

	- 指令或功能可能需要使用相同的资源，如总线或内存。

- **过程依赖 (Procedural dependencies)**: 

	- 执行哪条指令取决于另一条指令的结果，例如跳转和条件分支。

- **数据依赖 (Data dependencies)**: 

	- 一条指令需要另一条指令的结果才能执行。例如，减法可能需要知道前一条指令执行时是否产生了进位。

## 3. 超标量处理器 (Superscalar Processors)

### **概念**: 可以同时执行两条或更多条指令的处理器。这被称为指令级并行。

### Pentium 的实现:

- Pentiums 包含两个执行单元 U 和 V。

- 如果两条指令都是简单的，并且没有依赖关系，它们可以并行执行。

- 简单指令是硬件实现的。

### **编译器挑战**: 编译器需要意识到许多可能的冲突，如数据依赖、过程依赖和资源冲突。

### 局限：

- 程序依赖（Data dependancy）：执行哪条指令取决于另一条指令的结果，例如跳转和条件分支。

- 数据依赖 ：一条指令需要另一条指令的结果才能执行。例如，减法可能需要知道前一条指令执行时是否产生了进位。

	- 在r1 完成加法操作之前，无法移入r3,,因此这样两种指令无法并行

- 指令或功能可能需要使用相同的资源，如总线或内存。

	- 资源冲突：r2，r3 两个寄存器 都需要 r1 

## 4. 向量处理器 (Vector Processors)

### **概念**: 

- 许多问题需要对存储在数组（或向量）中的值进行重复计算。向量处理器使用并行的 ALU（算术逻辑单元）来并行执行这些操作。

### **指令**: `Vector C = Vector A + Vector B`。

### 实现方式:

- **并行 ALU**: 多个 ALU 并行工作。

	- 为何并行

	- 架构

- 流水线 ALU (Pipelined ALU):

	- 向量处理器中的 ALU 可以串联排列，形成流水线化的 ALU。

	- 这是更常见的向量处理器形式。

	- 实现架构

	- 加速原因:

		- ALU 流水线。

		- CPU 为 ALU 顺序提取数据，一条指令会导致 CPU 提取整个向量。

		- 孤立的浮点计算不会被加速。

- 执行流程

### 链接 (Chaining):

- 结果可以在流水线中从一个 ALU 传递到另一个 ALU。

- 由于计算的中间结果不必离开 ALU 进行后续计算，因此加快了计算速度。

## 5. 并行处理器 (Parallel Processors)

### 基本概念:

- 并行处理器包含多个控制单元。

- 流水线、多 ALU 和协处理器是低级别的并行处理，但只使用一个控制单元。

### Flynn 的分类:

- **SISD (Single Instruction, Single Data stream)**: 单处理器，通过流水线实现并行。

- **SIMD (Single Instruction, Multiple Data stream)**: 单指令控制多个处理元件，如向量处理器。

- **MIMD (Multiple Instruction, Multiple Data stream)**: 

	- 定义：

		- 一组处理器同时在不同的数据集上执行不同的指令。

	- 类型：

		- 多处理器 (Multiprocessor):

			- 共享内存，处理器通过共享内存进行通信。

			- 很难扩展。

		- 多计算机 (Multicomputer):

			- 每个处理器都有自己的内存。

			- 处理器之间有专用的通信路径。

			- 易于扩展（例如，互联网）。

		- 并行虚拟机（PVM ParallelVirtual Machine）

			- 可以使网络将Unix（和NT）计算机用作单个分布式内存并行计算机。 

			- Unix (and NT) computers to be used as a single distributed 

			- memory parallel computer.

	- MIMD 互连拓扑 (Interconnection Topologies):

		- **类型**: 环形 (Ring)、网格 (Mesh)、树形 (Tree)、超立方体 (Hypercube)。

		- 距离:

			- **环形**: n 个节点的最大距离是 n/2。

			- **网格**: n x n 网格的最大距离是 2 (n-1)。

			- **超立方体**: N = 2^n 个处理器，每个处理器有 n 个链接，直径为 n。

### 并行编程:

- 标量：

- 向量：

- 并行处理：

- 指令：

	- **FORK**: 派生出独立进程。

	- **JOIN**: 等待 N 个进程完成后再继续。

## 6. 系统类型 (System Types)

### 个人计算机系统 (Personal-Computer Systems)

- 专用于单个用户的计算机系统。

- 操作系统设计的目的不是最大化 CPU 使用率，而是最大化用户使用的便利性和响应性。

- 单用户系统的设计思想是从早期的大型多用户系统迁移过来的。

### 并行系统 (Parallel Systems)

- **趋势**: 大多数计算机只有一个处理器，但趋势是多处理器系统。

- **紧密耦合 (Tightly Coupled)**: 处理器共享总线、时钟和外设，通过共享内存通信。

- **容错性 (Fault Tolerance)**: 如果并行系统中的单个处理器发生故障，理论上其他进程可以继续运行（尽管速度稍慢），这被称为优雅降级。

- **Tandem 系统**: 在两个处理器上同时运行每个进程的两个副本，用于备份。

- **对称系统 (Symmetric Systems)**: 每个处理器运行一个相同的操作系统副本。

- **非对称系统 (Asymmetric Systems)**: 每个处理器被分配一个特定的任务，由一个主处理器控制任务分配。

### 分布式系统 (Distributed Systems)

- 处理器不共享公共内存或时钟。

- 进程之间的通信通过专用通信线路进行。

- 也称为松散耦合系统或多计算机系统。

- **Beowulf**: 一个包含 16 台计算机的集群，总共有 3200 MHz 和 2Gb 的 RAM。

### 并行 / 分布式系统的优势 (Benefits)

- **资源共享**: 一个站点的用户可以使用另一个站点的资源。

- **计算加速**: 并发运行同一程序的不同部分可以加速计算。

- **可靠性**: 如果系统中有足够的冗余，一个站点的故障不会停止整个系统。

- **通信**: 允许信息在远距离共享。

